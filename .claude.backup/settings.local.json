{
  "permissions": {
    "allow": [
      "Bash(find:*)",
      "Bash(bin/rails runner:*)",
      "Bash(docker compose exec:*)",
      "Bash(claude task create:*)",
      "Bash(bash:*)",
      "Bash(docker compose:*)",
      "Bash(./hack/spec_metadata.sh:*)",
      "Bash(git checkout:*)",
      "Bash(chmod:*)",
      "Bash(./hack/generate_frontmatter.sh:*)",
      "Bash(mkdir:*)",
      "Bash(curl:*)",
      "Bash(cat:*)",
      "Bash(bundle list:*)",
      "Bash(gem list)",
      "Bash(docker-compose exec rails-mrp-api gem:*)",
      "Bash(git log:*)",
      "Bash(git init:*)",
      "Bash(git add:*)",
      "Bash(git commit:*)",
      "Bash(git remote add:*)",
      "Bash(git branch:*)",
      "WebSearch",
      "Bash(claude-agent academic-researcher \"Research academic literature on vector similarity algorithms for recommendation systems.\n\nFocus areas:\n- Mathematical foundations and computational complexity of similarity metrics (cosine similarity, Euclidean distance, dot product, Manhattan distance, Jaccard similarity)\n- Theoretical trade-offs between different distance metrics in high-dimensional spaces\n- Academic studies comparing algorithm performance and accuracy\n- Approximate Nearest Neighbor (ANN) algorithm theory: HNSW, IVF, LSH, Product Quantization\n- Embedding space theory and dimensionality considerations\n- Research on scalability and computational complexity (time/space trade-offs)\n\nDepth: Deep (this is foundational theory requiring thorough academic investigation)\nKey concepts: vector similarity, distance metrics, ANN algorithms, computational complexity, embedding spaces, curse of dimensionality\nTimeframe: Include foundational papers (2010+) and recent advances (2020-2025)\n\nReturn: Peer-reviewed studies, algorithm complexity analysis, comparative benchmarks, theoretical foundations, consensus areas and debates\")",
      "Bash(claude-agent industry-researcher \"Research industry practices and expert insights on vector-based recommendation systems at scale.\n\nFocus areas:\n- How Netflix, Spotify, YouTube, Amazon implement vector similarity for recommendations\n- Real-world architecture patterns: two-tower models, bi-encoders, embedding generation pipelines\n- Production implementations using FAISS, HNSW, Annoy, ScaNN, and vector databases (Pinecone, Milvus, Qdrant, Weaviate)\n- Performance optimization strategies: GPU acceleration, distributed search, caching, index tuning\n- Scaling considerations: billion-scale datasets, latency requirements, throughput optimization\n- Trade-offs between accuracy (recall) and speed in production systems\n- Infrastructure costs and resource utilization patterns\n- Best practices for embedding model training and deployment\n\nDepth: Deep (comprehensive investigation of production systems and scaling strategies)\nTarget sources: Engineering blogs from major tech companies, conference talks (RecSys, KDD), vector database vendor documentation, case studies with metrics\nEvidence type: Architecture diagrams, performance metrics, implementation patterns, post-mortems, benchmark comparisons\n\nReturn: Production architectures, case studies with metrics, scaling strategies, best practices, expert recommendations, cost/performance trade-offs\")",
      "WebFetch(domain:arxiv.org)",
      "WebFetch(domain:engineering.atspotify.com)",
      "WebFetch(domain:netflixtechblog.com)",
      "WebFetch(domain:blog.algomaster.io)",
      "WebFetch(domain:api7.ai)",
      "WebFetch(domain:konghq.com)",
      "WebFetch(domain:gist.github.com)",
      "WebFetch(domain:github.blog)",
      "Bash(claude-agent academic-researcher \"Research academic literature on LLM sycophancy, RLHF alignment issues, and critical thinking in AI systems.\n\nFocus areas:\n- Root causes of sycophancy in RLHF training (reward hacking, preference collapse)\n- Studies on interventions to reduce sycophancy (prompt-based, training-based)\n- Research on critical thinking and reasoning in LLMs\n- Constitutional AI and critique-revision mechanisms\n- Evaluation metrics for measuring sycophancy vs honest disagreement\n- Cognitive biases in AI systems (confirmation bias, agreement bias)\n\nDepth: Deep (this is foundational AI safety research)\nKey concepts: sycophancy, RLHF, reward tampering, Constitutional AI, AI alignment, truthfulness\nTimeframe: Focus on 2023-2025 research (this is a rapidly evolving field) but include foundational papers\n\nReturn: Studies with methodology quality, key findings, consensus areas, and open questions. Prioritize papers from Anthropic, OpenAI, academic labs studying alignment.\")",
      "Bash(claude-agent industry-researcher \"Research industry practices and prompt engineering techniques for encouraging critical thinking and reducing sycophancy in LLMs.\n\nFocus areas:\n- Anthropic and OpenAI''s published system prompts and approaches\n- Practical prompt patterns for critical thinking (devil''s advocate, perspective-shifting)\n- Persona design for ''critical professor'' or ''rigorous reviewer'' behaviors\n- Reusable prompt templates and ''modes'' for different AI interfaces\n- Best practices from prompt engineering practitioners\n- Case studies of effective anti-sycophancy prompts\n- How to structure system prompts vs user prompts for this goal\n- Making prompts work across Claude, ChatGPT, and other interfaces\n\nDepth: Deep (need comprehensive collection of practical techniques and templates)\nTarget sources: Anthropic blog, OpenAI documentation, prompt engineering communities, AI safety practitioners\nEvidence type: Working prompt templates, before/after examples, practitioner testimonials\n\nReturn: Specific prompt templates, best practices with examples, expert recommendations, and guidance on creating reusable ''modes''.\")",
      "WebFetch(domain:techcrunch.com)",
      "WebFetch(domain:cybercorsairs.com)",
      "WebFetch(domain:openai.com)",
      "WebFetch(domain:github.com)",
      "Read(//Users/seankim/Wooj Dropbox/Utilities/epub/**)"
    ],
    "deny": [],
    "ask": []
  }
}
